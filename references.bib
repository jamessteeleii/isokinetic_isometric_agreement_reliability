@article{berchtoldTestRetestAgreement2016,
  title = {Test--Retest: {{Agreement}} or Reliability?},
  shorttitle = {Test--Retest},
  author = {Berchtold, Andr{\'e}},
  year = {2016},
  month = jan,
  journal = {Methodological Innovations},
  volume = {9},
  pages = {2059799116672875},
  publisher = {SAGE Publications Ltd},
  issn = {2059-7991},
  doi = {10.1177/2059799116672875},
  urldate = {2024-09-22},
  abstract = {Test--retest is a concept that is routinely evaluated during the validation phase of many measurement tools. However, this term covers at least two related but very different concepts: reliability and agreement. Reliability is the ability of a measure applied twice upon the same respondents to produce the same ranking on both occasions. Agreement requires the measurement tool to produce twice the same exact values. An analysis of research papers showed that the distinction between both concepts remains anything but clear, and that the current practice is to evaluate reliability only, generally on the basis of the sole Pearson's correlation. This practice is very problematic in the context of longitudinal studies because it becomes difficult to determine whether a difference between two successive observations is attributable to a real change of the respondents or only to the characteristics of the measurement tool, which then leads to a possible misinterpretation of the results. More focus should be given on the real interpretation of linear correlation, and when agreement is required in addition to reliability, then correct alternative, such as the Bland--Altman plot, should be more generally used.},
  langid = {english},
  file = {C:\Users\james\Zotero\storage\K26QUU68\Berchtold - 2016 - Test–retest Agreement or reliability.pdf}
}

@article{blandStatisticalMethodsAssessing1986a,
  title = {Statistical Methods for Assessing Agreement between Two Methods of Clinical Measurement},
  author = {Bland, J. M. and Altman, D. G.},
  year = {1986},
  month = feb,
  journal = {Lancet (London, England)},
  volume = {1},
  number = {8476},
  pages = {307--310},
  issn = {0140-6736},
  abstract = {In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old. Such investigations are often analysed inappropriately, notably by using correlation coefficients. The use of correlation is misleading. An alternative approach, based on graphical techniques and simple calculations, is described, together with the relation between this analysis and the assessment of repeatability.},
  langid = {english},
  pmid = {2868172},
  keywords = {Diagnosis,Humans,Peak Expiratory Flow Rate,Statistics as Topic}
}

@article{christensenJonesAlsMethod2020,
  title = {On {{Jones}} et al.'s Method for Extending {{Bland-Altman}} Plots to Limits of Agreement with the Mean for Multiple Observers},
  author = {Christensen, Heidi S. and Borgbjerg, Jens and B{\o}rty, Lars and B{\o}gsted, Martin},
  year = {2020},
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {20},
  number = {1},
  pages = {304},
  issn = {1471-2288},
  doi = {10.1186/s12874-020-01182-w},
  urldate = {2024-09-22},
  abstract = {To assess the agreement of continuous measurements between a number of observers, Jones et al. introduced limits of agreement with the mean (LOAM) for multiple observers, representing how much an individual observer can deviate from the mean measurement of all observers. Besides the graphical visualisation of LOAM, suggested by Jones et al., it is desirable to supply LOAM with confidence intervals and to extend the method to the case of multiple measurements per observer.},
  keywords = {Accuracy,Confidence intervals,Continuous measurements,Limits of agreement with the mean},
  file = {C\:\\Users\\james\\Zotero\\storage\\5E3WR5VS\\Christensen et al. - 2020 - On Jones et al.’s method for extending Bland-Altman plots to limits of agreement with the mean for m.pdf;C\:\\Users\\james\\Zotero\\storage\\EUXFAK5T\\s12874-020-01182-w.html}
}

@article{jonesGraphicalMethodAssessing2011,
  title = {A Graphical Method for Assessing Agreement with the Mean between Multiple Observers Using Continuous Measures},
  author = {Jones, Mark and Dobson, Annette and O'Brian, Sue},
  year = {2011},
  month = oct,
  journal = {International Journal of Epidemiology},
  volume = {40},
  number = {5},
  pages = {1308--1313},
  issn = {0300-5771},
  doi = {10.1093/ije/dyr109},
  urldate = {2024-09-22},
  abstract = {Background Currently, we are not aware of a method to assess graphically on one simple plot agreement between more than two observers making continuous measurements on the same subjects.Methods We aimed to develop a simple graphical method to assess agreement between multiple observers using continuous measurements. The Bland--Altman graphical method for assessing agreement between two observers using continuous measures was modified and extended to accommodate multiple observers. Mathematical formulae are derived and real data examples used to illustrate the proposed method.Results The examples show that the proposed graphical method of assessing agreement provides clinically useful information. This information includes estimates of the limits of agreement with the mean and a visual means for determining these limits over the range of measurements. In a data example that included five readers' measurements of 40 lung lesions, the intra-class correlation (ICC) was 0.84 indicating readers can reliably measure the lesions. However, the estimated limits of agreement with the mean were -1.1 to 1.1\,cm implying that the readers' measurements can plausibly differ from the mean estimated tumour size by more than 1\,cm. This is a clinically significant difference according to the study authors. In addition, a plot of the limits of agreement with the mean by mean tumour size shows heterogeneous agreement presumably due to the varying degrees of definition at the edge of the lesions.Conclusions The proposed graphical method of assessing agreement can be used alongside other measures such as ICC for reporting on reproducibility in studies of multiple observers making continuous measurements.},
  file = {C\:\\Users\\james\\Zotero\\storage\\NM7V44NI\\Jones et al. - 2011 - A graphical method for assessing agreement with the mean between multiple observers using continuous.pdf;C\:\\Users\\james\\Zotero\\storage\\TVR9YVFH\\658431.html}
}

@article{kottnerDifferenceReliabilityAgreement2011,
  title = {The Difference between Reliability and Agreement},
  author = {Kottner, Jan and Streiner, David L.},
  year = {2011},
  month = jun,
  journal = {Journal of Clinical Epidemiology},
  volume = {64},
  number = {6},
  pages = {701--702},
  publisher = {Elsevier},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2010.12.001},
  urldate = {2024-09-22},
  langid = {english},
  pmid = {21411278},
  file = {C:\Users\james\Zotero\storage\DV3BIQJ8\Kottner and Streiner - 2011 - The difference between reliability and agreement.pdf}
}

@article{kruschkeBayesianNewStatistics2018,
  type = {Journal Article},
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  author = {Kruschke, John K and Liddell, Torrin M},
  year = {2018},
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  pages = {178--206},
  issn = {1069-9384}
}

@article{nuzzoCORPMeasurementUpper2019,
  title = {{{CORP}}: {{Measurement}} of Upper and Lower Limb Muscle Strength and Voluntary Activation},
  shorttitle = {{{CORP}}},
  author = {Nuzzo, James L. and Taylor, Janet L. and Gandevia, Simon C.},
  year = {2019},
  month = mar,
  journal = {Journal of Applied Physiology},
  volume = {126},
  number = {3},
  pages = {513--543},
  publisher = {American Physiological Society},
  issn = {8750-7587},
  doi = {10.1152/japplphysiol.00569.2018},
  urldate = {2024-09-22},
  abstract = {Muscle strength, the maximal force-generating capacity of a muscle or group of muscles, is regularly assessed in physiological experiments and clinical trials. An understanding of the expected variation in strength and the factors that contribute to this variation is important when designing experiments, describing methodologies, interpreting results, and attempting to replicate methods of others and reproduce their findings. In this review (Cores of Reproducibility in Physiology), we report on the intra- and inter-rater reliability of tests of upper and lower limb muscle strength and voluntary activation in humans. Isometric, isokinetic, and isoinertial strength exhibit good intra-rater reliability in most samples (correlation coefficients {$\geq$}0.90). However, some tests of isoinertial strength exhibit systematic bias that is not resolved by familiarization. With the exception of grip strength, few attempts have been made to examine inter-rater reliability of tests of muscle strength. The acute factors most likely to affect muscle strength and serve as a source of its variation from trial-to-trial or day-to-day include attentional focus, breathing technique, remote muscle contractions, rest periods, temperature (core, muscle), time of day, visual feedback, body and limb posture, body stabilization, acute caffeine consumption, dehydration, pain, fatigue from preceding exercise, and static stretching {$>$}60 s. Voluntary activation, the nervous system's ability to drive a muscle to create its maximal force, exhibits good intra-rater reliability when examined with twitch interpolation (correlation coefficients {$>$}0.80). However, inter-rater reliability has not been formally examined. The methodological factors most likely to influence voluntary activation are myograph compliance and sensitivity; stimulation location, intensity, and inadvertent stimulation of antagonists; joint angle (muscle length); and the resting twitch.},
  keywords = {force,isoinertial,isokinetic,isometric,muscle strength,voluntary activation},
  file = {C:\Users\james\Zotero\storage\YRGV6CZV\Nuzzo et al. - 2019 - CORP Measurement of upper and lower limb muscle strength and voluntary activation.pdf}
}

@misc{rodriguez-sanchezGratefulFacilitateCitation2023,
  title = {Grateful: {{Facilitate Citation}} of {{R Packages}}},
  shorttitle = {Grateful},
  author = {{Rodriguez-Sanchez}, Francisco and {cre} and {cph} and Jackson, Connor P. and Hutchins, Shaurita D. and Clawson, James M.},
  year = {2023},
  month = oct,
  urldate = {2024-07-10},
  abstract = {Facilitates the citation of R packages used in analysis projects. Scans project for packages used, gets their citations, and produces a document with citations in the preferred bibliography format, ready to be pasted into reports or manuscripts. Alternatively, 'grateful' can be used directly within an 'R Markdown' or 'Quarto' document.},
  copyright = {MIT + file LICENSE}
}

@article{schluterMultivariateHierarchicalBayesian2009,
  title = {A Multivariate Hierarchical {{Bayesian}} Approach to Measuring Agreement in Repeated Measurement Method Comparison Studies},
  author = {Schluter, Philip J.},
  year = {2009},
  month = jan,
  journal = {BMC Medical Research Methodology},
  volume = {9},
  number = {1},
  pages = {6},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-9-6},
  urldate = {2024-09-22},
  abstract = {Assessing agreement in method comparison studies depends on two fundamentally important components; validity (the between method agreement) and reproducibility (the within method agreement). The Bland-Altman limits of agreement technique is one of the favoured approaches in medical literature for assessing between method validity. However, few researchers have adopted this approach for the assessment of both validity and reproducibility. This may be partly due to a lack of a flexible, easily implemented and readily available statistical machinery to analyse repeated measurement method comparison data.},
  keywords = {Automate Machine,Credible Region,Hierarchical Bayesian Model,Step Count,Subject Variance},
  file = {C\:\\Users\\james\\Zotero\\storage\\AK3GU8K7\\Schluter - 2009 - A multivariate hierarchical Bayesian approach to measuring agreement in repeated measurement method.pdf;C\:\\Users\\james\\Zotero\\storage\\4HSVCZ8C\\1471-2288-9-6.html}
}

@article{vetWhenUseAgreement2006a,
  title = {When to Use Agreement versus Reliability Measures},
  author = {de Vet, Henrica C. W. and Terwee, Caroline B. and Knol, Dirk L. and Bouter, Lex M.},
  year = {2006},
  month = oct,
  journal = {Journal of Clinical Epidemiology},
  volume = {59},
  number = {10},
  pages = {1033--1039},
  publisher = {Elsevier},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2005.10.015},
  urldate = {2024-09-22},
  langid = {english},
  pmid = {16980142},
  keywords = {Agreement,Measurement error,Measurement instruments,Reliability,Repeated measurements,Reproducibility},
  file = {C:\Users\james\Zotero\storage\SSAFHXP9\Vet et al. - 2006 - When to use agreement versus reliability measures.pdf}
}
